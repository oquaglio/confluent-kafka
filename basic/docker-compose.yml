version: '3'
services:
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-broker
    ports:
      - "9092:9092"  # External access for clients
    environment:
      # Basic broker settings
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  # Single broker, so 1 replica
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # KRaft mode settings (no ZooKeeper)
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      # Generate a unique cluster ID (run `kafka-storage.sh random-uuid` in container if needed)
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk  # Static example; replace with your own
    volumes:
      - kafka-data:/tmp/kraft-combined-logs  # Persist data between restarts

volumes:
  kafka-data:
